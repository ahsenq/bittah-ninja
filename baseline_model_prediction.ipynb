{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow import keras\n",
    "# from tensorflow.keras.layers import (Activation, Conv2D, Dense, Dropout, Flatten,\n",
    "#                           MaxPooling2D)\n",
    "# from tensorflow.keras.models import Model, Sequential\n",
    "# from tensorflow.keras.utils import Sequence\n",
    "from CNN_singleImage_baseline import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(\"GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['simpleCNN_1000epochs_20191112_024957.h5',\n",
       " 'train.pickle',\n",
       " 'simpleCNN_1000epochs_20191110_153647.h5',\n",
       " 'simpleCNN_1000epochs_20191110_171702.h5',\n",
       " 'test.pickle',\n",
       " 'simpleCNN_history_10epochs_20191109_192747.pickle',\n",
       " 'simpleCNN_10epochs_20191109_192747.h5',\n",
       " 'simpleCNN_history_1000epochs_20191110_150328.pickle',\n",
       " 'simpleCNN_100epochs_20191110_033120.h5',\n",
       " 'simpleCNN_history_1000epochs_20191110_153647.pickle',\n",
       " 'simpleCNN_history_1000epochs_20191110_171702.pickle',\n",
       " 'simpleCNN_history_100epochs_20191110_033120.pickle',\n",
       " 'simpleCNN_1000epochs_20191110_150328.h5',\n",
       " 'predictions.pickle',\n",
       " 'simpleCNN_history_1000epochs_20191112_024957.pickle']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "modelpath = '/data/models/'\n",
    "os.listdir(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelfile = 'simpleCNN_1000epochs_20191112_024957.h5'\n",
    "model = keras.models.load_model(os.path.join(modelpath, modelfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524 524\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(modelpath, 'test.pickle'), 'rb') as f:\n",
    "    x_test, y_test = pickle.load(f)\n",
    "print(len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_generator = DataGenerator(x_test, y_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([479,  26,   0,   0,   1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred > 0.5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "y_prob = copy.copy(y_pred)\n",
    "y_pred = (y_pred > 0.5).astype(np.int)\n",
    "with open(os.path.join(modelpath, 'predictions.pickle'), 'wb') as f:\n",
    "    pickle.dump((y_prob, y_pred), f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelPath = 'week11_all_assigned.csv'\n",
    "df = pd.read_csv(labelPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "-1.0       53\n",
       " 0.0     1892\n",
       " 1.0      497\n",
       " 2.0       22\n",
       " 3.0      132\n",
       " 4.0       76\n",
       " 99.0    2769\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_files = []\n",
    "for file in df.clip_title:\n",
    "    newfile = ''.join(file.split('.mp4')) + '.mp4'\n",
    "    new_files.append(newfile)\n",
    "df['clip_title'] = new_files\n",
    "df['label'] = df['class']\n",
    "df.drop(columns=['class'], inplace=True)\n",
    "df.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    1892\n",
       "1.0     497\n",
       "2.0      22\n",
       "3.0     132\n",
       "4.0      76\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[df.label != -1]\n",
    "df = df.loc[df.label != 99]\n",
    "df.groupby('label').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2619, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vidPath = '/data/vids/scaled'\n",
    "filenames = [f.split('.mp4')[0] + '_scaled.mp4' for f in df.clip_title]\n",
    "# filenames = [os.path.join(vidPath, f) for f in filenames]\n",
    "# labels = df.punch.tolist()\n",
    "labels = df.label.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clip_title'] = filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames2 = [x.split('/')[-1] for x in x_test]\n",
    "df2['clip_title'] = filenames2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_title</th>\n",
       "      <th>video-UID</th>\n",
       "      <th>labeler</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>downward_strike_punches_slice655_scaled.mp4</td>\n",
       "      <td>2857</td>\n",
       "      <td>Alex</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>downward_strike_punches_slice275_scaled.mp4</td>\n",
       "      <td>12907</td>\n",
       "      <td>Jen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>traditional_dance_slice415_scaled.mp4</td>\n",
       "      <td>5205</td>\n",
       "      <td>Jen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>V_789_slice325_scaled.mp4</td>\n",
       "      <td>12430</td>\n",
       "      <td>Ahsen</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>downward_strike_punches_slice850_scaled.mp4</td>\n",
       "      <td>13035</td>\n",
       "      <td>Lance</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>streetfight1_slice615_scaled.mp4</td>\n",
       "      <td>4441</td>\n",
       "      <td>Lance</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>streetfight4_slice410_scaled.mp4</td>\n",
       "      <td>15008</td>\n",
       "      <td>Jen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>521</td>\n",
       "      <td>V_991_scaled.mp4</td>\n",
       "      <td>12677</td>\n",
       "      <td>Lance</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>522</td>\n",
       "      <td>how_to_strike_max_power_slice180_scaled.mp4</td>\n",
       "      <td>13724</td>\n",
       "      <td>Lance</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>HShackeysack_slice345_scaled.mp4</td>\n",
       "      <td>251</td>\n",
       "      <td>Jen</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>524 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      clip_title  video-UID labeler  label\n",
       "0    downward_strike_punches_slice655_scaled.mp4       2857    Alex    0.0\n",
       "1    downward_strike_punches_slice275_scaled.mp4      12907     Jen    0.0\n",
       "2          traditional_dance_slice415_scaled.mp4       5205     Jen    0.0\n",
       "3                      V_789_slice325_scaled.mp4      12430   Ahsen    1.0\n",
       "4    downward_strike_punches_slice850_scaled.mp4      13035   Lance    0.0\n",
       "..                                           ...        ...     ...    ...\n",
       "519             streetfight1_slice615_scaled.mp4       4441   Lance    0.0\n",
       "520             streetfight4_slice410_scaled.mp4      15008     Jen    0.0\n",
       "521                             V_991_scaled.mp4      12677   Lance    0.0\n",
       "522  how_to_strike_max_power_slice180_scaled.mp4      13724   Lance    0.0\n",
       "523             HShackeysack_slice345_scaled.mp4        251     Jen    0.0\n",
       "\n",
       "[524 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.merge(df, how='inner', on='clip_title')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/w210/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(524, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "ohe_labels = ohe.fit_transform(df2['label'].values.reshape(-1,1))\n",
    "ohe_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHots = []\n",
    "ohe_labels = ohe_labels.toarray()\n",
    "for i in range(ohe_labels.shape[0]):\n",
    "    oneHots.append(ohe_labels[i])\n",
    "len(oneHots), len(oneHots[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['ohe_labels'] = oneHots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 5, 524, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = []\n",
    "preds = []\n",
    "for i in range(y_prob.shape[0]):\n",
    "    probs.append(y_prob[i])\n",
    "    preds.append(y_pred[i])\n",
    "len(probs), len(probs[0]), len(preds), len(preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['y_prob'] = probs\n",
    "df2['y_pred'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order is maintained\n",
    "for i,f in enumerate(filenames2):\n",
    "    if f != df2.clip_title[i]:\n",
    "        print(i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(os.path.join(modelpath, 'predictions.pickle'), 'wb') as f:\n",
    "#     pickle.dump((y_prob, y_pred), f, protocol=-1)\n",
    "df2.to_pickle(os.path.join(modelpath, 'predictions.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_title</th>\n",
       "      <th>video-UID</th>\n",
       "      <th>labeler</th>\n",
       "      <th>label</th>\n",
       "      <th>ohe_labels</th>\n",
       "      <th>y_prob</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>downward_strike_punches_slice655_scaled.mp4</td>\n",
       "      <td>2857</td>\n",
       "      <td>Alex</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.91471887, 0.04957079, 3.3734228e-05, 0.0336...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>downward_strike_punches_slice275_scaled.mp4</td>\n",
       "      <td>12907</td>\n",
       "      <td>Jen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.7162727, 0.13020208, 0.0011639277, 0.133737...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>traditional_dance_slice415_scaled.mp4</td>\n",
       "      <td>5205</td>\n",
       "      <td>Jen</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.76954263, 0.19615111, 0.008012304, 0.012842...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>V_789_slice325_scaled.mp4</td>\n",
       "      <td>12430</td>\n",
       "      <td>Ahsen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.35030097, 0.64757156, 0.0005246858, 0.00062...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>downward_strike_punches_slice850_scaled.mp4</td>\n",
       "      <td>13035</td>\n",
       "      <td>Lance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>[0.73543257, 0.07232628, 1.3397551e-05, 0.1898...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    clip_title  video-UID labeler  label  \\\n",
       "0  downward_strike_punches_slice655_scaled.mp4       2857    Alex    0.0   \n",
       "1  downward_strike_punches_slice275_scaled.mp4      12907     Jen    0.0   \n",
       "2        traditional_dance_slice415_scaled.mp4       5205     Jen    0.0   \n",
       "3                    V_789_slice325_scaled.mp4      12430   Ahsen    1.0   \n",
       "4  downward_strike_punches_slice850_scaled.mp4      13035   Lance    0.0   \n",
       "\n",
       "                  ohe_labels  \\\n",
       "0  [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "1  [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "2  [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "3  [0.0, 1.0, 0.0, 0.0, 0.0]   \n",
       "4  [1.0, 0.0, 0.0, 0.0, 0.0]   \n",
       "\n",
       "                                              y_prob           y_pred  \n",
       "0  [0.91471887, 0.04957079, 3.3734228e-05, 0.0336...  [1, 0, 0, 0, 0]  \n",
       "1  [0.7162727, 0.13020208, 0.0011639277, 0.133737...  [1, 0, 0, 0, 0]  \n",
       "2  [0.76954263, 0.19615111, 0.008012304, 0.012842...  [1, 0, 0, 0, 0]  \n",
       "3  [0.35030097, 0.64757156, 0.0005246858, 0.00062...  [0, 1, 0, 0, 0]  \n",
       "4  [0.73543257, 0.07232628, 1.3397551e-05, 0.1898...  [1, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('/data/models/predictions.pickle')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
