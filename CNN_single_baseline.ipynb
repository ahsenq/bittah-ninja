{"cells":[{"source":["import argparse\n","import os\n","import pickle\n","import sys\n","from collections import Counter\n","\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","import keras\n","from keras.layers import (Activation, Conv2D, Dense, Dropout, Flatten,\n","                          MaxPooling2D)\n","from keras.models import Model, Sequential\n","from keras.utils import Sequence\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--vidpath', default='vids/scaled')\n","parser.add_argument('--epochs', default=10, type=int)\n","parser.add_argument('--batch_size', default=32, type=int)\n","try:\n","    args = parser.parse_args()\n","except:\n","    args = parser.parse_args([])\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# labelPath = 'bittah-ninja/first_1k_labeled_long_vids_removed.csv'\n","labelPath = 'first_1k_labeled_long_vids_removed.csv'\n","# labelPath = 'full_labels.csv'\n","df = pd.read_csv(labelPath)\n","new_files = []\n","for file in df.clip_title:\n","    newfile = ''.join(file.split('.mp4')) + '.mp4'\n","    new_files.append(newfile)\n","df['clip_title'] = new_files\n","# df['label'] = df['class']\n","# df.drop(columns=['class'], inplace=True)\n","df.groupby('label').size()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["df = df.loc[df.label != -1]\n","df.groupby('label').size()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["df.shape"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# df['punch'] = (df.label != 0).astype('int')\n","# df.groupby('punch').size()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["vidPath = args.vidpath\n","filenames = [f.split('.mp4')[0] + '_scaled.mp4' for f in df.clip_title]\n","filenames = [os.path.join(vidPath, f) for f in filenames]\n","# labels = df.punch.tolist()\n","labels = df.label.tolist()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# def getMaxFrameCount(filenames):\n","#     frameCount = []\n","#     for file in tqdm(filenames):\n","#         cap = cv2.VideoCapture(file)\n","#         frameCount.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n","\n","#     return max(frameCount)\n","\n","\n","class DataGenerator(Sequence):\n","\n","    def __init__(self,\n","                 filenames,\n","                 labels,\n","                 batch_size,\n","                 frame_height=224,\n","                 frame_width=224,\n","                 n_channels=1):\n","        self.filenames = filenames\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.h = frame_height\n","        self.w = frame_width\n","        self.n_channels = n_channels\n","\n","    def __len__(self):\n","        return np.ceil(len(self.filenames) / self.batch_size).astype(int)\n","\n","    def __data_generation(self, idx_list):\n","        def getSingleFrame(filepath):\n","            cap = cv2.VideoCapture(filepath)\n","            vid = []\n","            while cap.isOpened():\n","                ret, frame = cap.read()\n","                if ret:\n","                    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","                    gray = cv2.resize(gray, (self.h, self.w))\n","                    vid.append(gray)\n","                    if cv2.waitKey(1) & 0xFF == ord('q'):\n","                        break\n","                else:\n","                    break\n","            cap.release()\n","            j = int(np.random.choice(len(vid), 1))\n","            frame = vid[j]\n","            return frame\n","\n","        x = np.empty((self.batch_size,\n","                      self.w,\n","                      self.h,\n","                      self.n_channels), dtype=np.float16)\n","        y = np.empty((self.batch_size), dtype=np.float16)\n","        for i, idx in enumerate(idx_list):\n","            file = self.filenames[idx]\n","            frame = getSingleFrame(file)\n","            frame = frame.reshape(self.w,\n","                                  self.h,\n","                                  self.n_channels)\n","            x[i, ] = frame\n","            y[i, ] = self.labels[idx]\n","            y = tf.keras.utils.to_categorical(y,\n","                                              num_classes=len(set(self.labels)),\n","                                              dtype='float16')\n","        # print(x.shape, y.shape)\n","        return x, y\n","        # yield x, y\n","\n","    def __getitem__(self, idx):\n","        batch = range(idx * self.batch_size, (idx + 1) * self.batch_size)\n","        x, y = self.__data_generation(batch)\n","        return x, y\n","        # yield x, y\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["batch_size = args.batch_size\n","labels_counts = Counter(labels)\n","# TODO: Not sure if this should be 1 - x or x\n","class_weight = {k:1-(v/len(labels)) for k,v in labels_counts.items()}"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["x_train, x_test, y_train, y_test = train_test_split(\n","    filenames, labels, test_size=0.2)\n","print(len(x_train), len(y_train))\n","print(len(x_test), len(y_test))"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# max_frame_count = getMaxFrameCount(filenames)\n","train_generator = DataGenerator(x_train,\n","                                y_train,\n","                                batch_size)\n","test_generator = DataGenerator(x_test,\n","                               y_test,\n","                               batch_size)\n","len(train_generator), len(test_generator)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# lab, batch = next(train_generator)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["input_shape = (224, 224, 1)\n","epochs = args.epochs\n","# model = Sequential()\n","inputs = keras.layers.Input(shape=input_shape, name='inputs')\n","conv = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","pool = MaxPooling2D(pool_size=(2, 2))(conv)\n","conv = Conv2D(32, (3, 3), activation='relu', padding='same')(pool)\n","pool = MaxPooling2D(pool_size=(2, 2))(conv)\n","# dropout = Dropout(0.25)(pool)\n","conv = Conv2D(32, (4, 4), activation='relu', padding='same')(pool)\n","pool = MaxPooling2D(pool_size=(2, 2))(conv)\n","conv = Conv2D(32, (4, 4), activation='relu', padding='same')(pool)\n","pool = MaxPooling2D(pool_size=(2, 2))(conv)\n","dropout = Dropout(0.25)(pool)\n","flat = Flatten()(dropout)\n","dense = Dense(16, activation='relu')(flat)\n","dropout = Dropout(0.25)(dense)\n","outputs = Dense(len(set(labels)), activation='softmax', name='outputs')(dropout)\n","model = Model(inputs, outputs)\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","model.summary()\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# inputs = keras.layers.Input(shape=input_shape, name='inputs')\n","# conv2D = keras.layers.Conv2D(1, kernel_size=(3,3))\n","# conv3 = Conv3D(4, (3, 3, 3), strides=(1, 1, 1), padding='same',\n","#                data_format='channels_last', activation='relu')(inputs)\n","# pool = keras.layers.MaxPooling3D(pool_size=(2, 2, 2),\n","#                                  strides=(2, 2, 2), padding='same',\n","#                                  data_format='channels_last')(conv3)\n","# drop = Dropout(0.5)(pool)\n","# flat = Flatten()(drop)\n","# # model.add(Dense(128, activation='relu'))\n","# # model.add(Dense(64, activation='relu'))\n","# outputs = Dense(1, activation='sigmoid')(flat)\n","# model = Model(inputs, outputs)\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":[""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["hist = model.fit_generator(generator=train_generator,\n","                           steps_per_epoch=(len(x_train) // batch_size),\n","                           epochs=1,\n","                           verbose=1,\n","                           validation_data=test_generator,\n","                           validation_steps=(len(x_test) // batch_size),\n","                           class_weight=class_weight,\n","                           use_multiprocessing=True)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Appendix"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["\n","\n","def getSingleFrame(filepath):\n","    cap = cv2.VideoCapture(filepath)\n","    vid = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if ret:\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            gray = cv2.resize(gray, (h, w))\n","            vid.append(gray)\n","            if cv2.waitKey(1) & 0xFF == ord('q'):\n","                break\n","        else:\n","            break\n","    cap.release()\n","    frame = np.random.choice(np.array(vid), 1)\n","    return frame\n","\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["batch_size = 4\n","w = 224\n","h = 224\n","n_channels = 1\n","idx_list = range(10)\n","x = np.empty((batch_size,\n","              w,\n","              h,\n","              n_channels), dtype=np.float16)\n","y = np.empty((batch_size), dtype=np.float16)\n","for i, idx in enumerate(idx_list):\n","    file = filenames[idx]\n","    cap = cv2.VideoCapture(file)\n","    vid = []\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if ret:\n","            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","            gray = cv2.resize(gray, (h, w))\n","            vid.append(gray)\n","            if cv2.waitKey(1) & 0xFF == ord('q'):\n","                break\n","        else:\n","            break\n","    cap.release()\n","    j = int(np.random.choice(len(vid), 1))\n","    frame = vid[j]\n","    # frame = getSingleFrame(file)\n","    frame = frame.reshape(w,\n","                          h,\n","                          n_channels)\n","    x[i, ] = frame\n","    y[i, ] = labels[idx]\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["filenames2 = [os.path.join(vidPath, f) for f in os.listdir(vidPath)]\n","[f for f in filenames if f in filenames2]\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["!pwd\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}